<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>Kafka programming with Java</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <h1 id="kafka-programming-with-java">Kafka programming with Java</h1>
<h2 id="1-kafka-client-libraries-sdks">1. Kafka Client libraries SDKs</h2>
<ul>
<li><strong><ins>About / Introduction</ins></strong>
<ul>
<li>We can use kafka client libraries to develop application client to communicate with Kafka server as a producer/consumer.</li>
</ul>
</li>
<li><strong><ins>Java SDKs</ins></strong>
<ul>
<li><strong>The official client library:</strong> <em>Low-level client</em>
<ul>
<li><strong>Gradle:</strong><pre><code class="language-json">    <span class="hljs-comment">// https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients</span>
    implementation &#x27;org.apache.kafka<span class="hljs-punctuation">:</span>kafka-clients<span class="hljs-punctuation">:</span><span class="hljs-number">3.9</span><span class="hljs-number">.0</span>&#x27;
</code></pre>
</li>
<li><strong>Maven:</strong><pre><code class="language-xml">    <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-clients<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.9.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span> <span class="hljs-comment">&lt;!-- check for latest release / compatibe version --&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
</code></pre>
</li>
</ul>
</li>
<li><strong>The official Kafka Streams client library:</strong> <em>To create your Kafka Streams application</em>
<ul>
<li><strong>Gradle:</strong><pre><code class="language-json">      <span class="hljs-comment">// https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams</span>
      implementation &#x27;org.apache.kafka<span class="hljs-punctuation">:</span>kafka-streams<span class="hljs-punctuation">:</span><span class="hljs-number">3.9</span><span class="hljs-number">.0</span>&#x27;
</code></pre>
</li>
<li><strong>Maven:</strong><pre><code class="language-xml">    <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-streams<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.9.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
</code></pre>
</li>
</ul>
</li>
<li><strong>Kafka for Spring Boot:</strong> Applies Spring concepts to Kafka development
<ul>
<li><strong>Reference:</strong> <a href="https://spring.io/projects/spring-kafka#overview">https://spring.io/projects/spring-kafka#overview</a></li>
<li><strong>Gradle:</strong><pre><code class="language-gradle">    <span class="hljs-comment">// https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka</span>
    implementation <span class="hljs-string">&#x27;org.springframework.kafka:spring-kafka:3.3.1&#x27;</span>
</code></pre>
</li>
<li><strong>Maven:</strong><pre><code class="language-xml">  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
</code></pre>
</li>
</ul>
</li>
<li><strong>Spring Cloud Stream:</strong> Bindings for Kafka Stream
<ul>
<li><strong>Reference:</strong> <a href="https://spring.io/projects/spring-cloud-stream">https://spring.io/projects/spring-cloud-stream</a></li>
<li><strong>Gradle:</strong><pre><code class="language-gradle">    <span class="hljs-comment">// https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-stream</span>
    implementation <span class="hljs-string">&#x27;org.springframework.cloud:spring-cloud-stream:4.2.0&#x27;</span>
    
    <span class="hljs-comment">// https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-stream-binder-kafka</span>
    implementation <span class="hljs-string">&#x27;org.springframework.cloud:spring-cloud-stream-binder-kafka:4.2.0&#x27;</span>

    <span class="hljs-comment">// https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka</span>
    implementation <span class="hljs-string">&#x27;org.springframework.kafka:spring-kafka:3.3.1&#x27;</span>
</code></pre>
</li>
<li><strong>Maven:</strong><pre><code class="language-xml">  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-stream<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-stream-binder-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>
</code></pre>
</li>
</ul>
</li>
<li><strong>Akka Streams &amp; Alpakka Kafka</strong>
<ul>
<li><strong>Documentation:</strong>
<ul>
<li><a href="https://doc.akka.io/libraries/akka-core/current/stream/index.html">https://doc.akka.io/libraries/akka-core/current/stream/index.html</a></li>
<li><a href="https://doc.akka.io/libraries/alpakka-kafka/current/home.html">https://doc.akka.io/libraries/alpakka-kafka/current/home.html</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://learn.conduktor.io/kafka/kafka-sdk-list/">https://learn.conduktor.io/kafka/kafka-sdk-list/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-kafka-client---hello-world">2. Kafka Client - Hello world</h2>
<h3 id="project-ref-a1-kafka-producer">Project ref: <a href="https://github.com/SRVivek1/kafka-for-beginners-2024/tree/main/03-kafka-beginners-gradle/a1-kafka-producer">a1-kafka-producer</a></h3>
<ul>
<li><strong><ins>Purpose / Feature</ins></strong>
<ul>
<li>This is xyz feature.</li>
</ul>
</li>
<li><strong><ins>Steps</ins></strong>
<ul>
<li><em><strong>Project Setup:</strong></em>
<ul>
<li>Create a gradle project using intellij IDEA IDE or by visiting <em><a href="https://start.spring.io/">https://start.spring.io/</a></em>.</li>
<li>Delete <code>src</code> folder from project home directory.</li>
</ul>
</li>
<li><em><strong>Step-1:</strong></em> Create a <em>new module</em> inside project.
<ul>
<li><strong>Steps:</strong> Right Click on the project --&gt; New --&gt; Module
<ul>
<li>Select appropriate option on the given form and click <em>Create</em>.</li>
</ul>
</li>
</ul>
</li>
<li><em><strong>Step-2:</strong></em> Add following dependencies.
<ul>
<li><strong>Kafka Clients:</strong> <em>implementation(&quot;org.apache.kafka:kafka-clients:3.9.0&quot;)</em></li>
<li><strong>Slf4j API:</strong> <em>implementation(&quot;org.slf4j:slf4j-api:2.0.16&quot;)</em></li>
<li><strong>Slf4j Simple:</strong> <em>implementation(&quot;org.slf4j:slf4j-simple:2.0.16&quot;)</em></li>
</ul>
</li>
<li><em><strong>Step-3:</strong></em> Create properties for target Kafka server.</li>
<li><em><strong>Step-4:</strong></em> Cretae Kafka ProducerRecord with <em>Topic name</em> &amp; <em>message</em> to be sent to topic.</li>
<li><em><strong>Step-5:</strong></em> Create Kafka Producer object using the <em>kafka properties</em>.</li>
<li><em><strong>Step-6:</strong></em> Pass the kafka record to <em>Kafka Producer</em> <em><strong>send(record)</strong></em> to send to topic.</li>
<li><em><strong>Step-7:</strong></em> Flush the data using <em>producer</em> instance.</li>
<li><em><strong>Step-8:</strong></em> Close the producer object/connection.</li>
</ul>
</li>
<li><strong><ins>Gradle / External dependency</ins></strong>
<ul>
<li>Required dependency.<pre><code class="language-groovy">      dependencies {
        implementation(<span class="hljs-string">&quot;org.apache.kafka:kafka-clients:3.9.0&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-api:2.0.16&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-simple:2.0.16&quot;</span>)
        testImplementation(platform(<span class="hljs-string">&quot;org.junit:junit-bom:5.9.1&quot;</span>))
        testImplementation(<span class="hljs-string">&quot;org.junit.jupiter:junit-jupiter&quot;</span>)
      }
</code></pre>
</li>
</ul>
</li>
<li><strong><ins>Code / Config changes</ins></strong>
<ul>
<li><strong>Producer:</strong> <em>KafkaProducerPoc.java</em>
<ul>
<li>imports
<ul>
<li><em>import org.apache.kafka.clients.producer.KafkaProducer;</em></li>
<li><em>import org.apache.kafka.clients.producer.ProducerRecord;</em></li>
<li><em>import org.apache.kafka.common.serialization.StringSerializer;</em></li>
<li><em>import java.util.Properties;</em></li>
</ul>
</li>
<li>Producer class to publish data to topics.<pre><code class="language-java">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">KafkaProducerPoc</span> {

      <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">logger</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(KafkaProducerPoc.class);

      <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {

          <span class="hljs-comment">// Create properties wit kafka configuration</span>
          <span class="hljs-keyword">final</span> <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();
          properties.setProperty(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;[::1]:9092&quot;</span>);
          properties.setProperty(<span class="hljs-string">&quot;key.serializer&quot;</span>, StringSerializer.class.getName());
          properties.setProperty(<span class="hljs-string">&quot;value.serializer&quot;</span>, StringSerializer.class.getName());

          <span class="hljs-comment">// Create kafka record to encapsulate the data</span>
          ProducerRecord&lt;String, String&gt; record1 = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerRecord</span>&lt;&gt;(<span class="hljs-string">&quot;demo_java&quot;</span>, <span class="hljs-string">&quot;Hello&quot;</span>);
          ProducerRecord&lt;String, String&gt; record2 = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerRecord</span>&lt;&gt;(<span class="hljs-string">&quot;demo_java&quot;</span>, <span class="hljs-string">&quot;World&quot;</span>);

          <span class="hljs-comment">// Create Kafka producer</span>
          <span class="hljs-keyword">final</span> KafkaProducer&lt;String, String&gt; producer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaProducer</span>&lt;&gt;(properties);

          producer.send(record1);
          producer.send(record2);

          <span class="hljs-comment">//flush and close</span>
          producer.flush();
          producer.close();
      }
  }
</code></pre>
</li>
<li><strong>Output: <em>Terminal</em></strong> <em><a href="http://kafka-console-consumer.sh">kafka-console-consumer.sh</a></em><pre><code class="language-properties">    <span class="hljs-attr">TBU</span>
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://www.javatpoint.com/creating-kafka-producer-in-java">https://www.javatpoint.com/creating-kafka-producer-in-java</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="3-kafka-producers-callbacks">3. Kafka Producers: callbacks</h2>
<h3 id="project-ref-a2-kafka-producer-with-callbacks">Project ref: <a href="https://github.com/SRVivek1/kafka-for-beginners-2024/tree/main/03-kafka-beginners-gradle/a2-kafka-producer-with-callbacks">a2-kafka-producer-with-callbacks</a></h3>
<ul>
<li><strong><ins>Purpose / Feature</ins></strong>
<ul>
<li>The callback is a function passed when sending data to topic. This function is implemented for asynchronously handling the request completion, hence <em>void</em> return type.</li>
<li>The callback function used by the producer is the <em>onCompletion()</em> with two arguments:
<ul>
<li><strong>Metadata of the Record:</strong>
<ul>
<li>Metadata of the record means fetching the information regarding the partition and its offsets.</li>
<li>If it is not null, an error will be thrown.</li>
</ul>
</li>
<li><strong>Exception:</strong>
<ul>
<li>Following are two exceptions which can be thrown while processing:
<ul>
<li><strong>Retriable exception:</strong>
<ul>
<li>This exception says that the message may be sent.</li>
</ul>
</li>
<li><strong>Non-retriable exception:</strong>
<ul>
<li>This exception throws the error that the message will never be sent.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>Steps</ins></strong>
<ul>
<li><em><strong>Project Setup:</strong></em> Develop kafka producer app.
<ul>
<li>Check <em>Section-2</em> for reference.</li>
</ul>
</li>
<li><em><strong>Step-1:</strong></em> Create and pass Kafka <em>Callback.java</em> class instance in send(...) method.
<ul>
<li>Add completion business logic inside <em>onCompletion(...)</em> method.</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>Gradle / External dependency</ins></strong>
<ul>
<li>Required dependency.<pre><code class="language-groovy">      dependencies {
        implementation(<span class="hljs-string">&quot;org.apache.kafka:kafka-clients:3.9.0&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-api:2.0.16&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-simple:2.0.16&quot;</span>)
      }
</code></pre>
</li>
</ul>
</li>
<li><strong><ins>Code / Config changes</ins></strong>
<ul>
<li><strong>Producer:</strong> <em>KafkaProducerPoc.java</em>
<ul>
<li>imports
<ul>
<li><em>import org.apache.kafka.clients.producer.Callback;</em></li>
<li><em>import org.apache.kafka.clients.producer.ProducerConfig;</em></li>
</ul>
</li>
<li>Producer class to publish data to topics with <em>Callback instance</em>.<pre><code class="language-java">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">KafkaProducerWithCallbacks</span> {

      <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">logger</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(KafkaProducerWithCallbacks.class);

      <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {
          logger.info(<span class="hljs-string">&quot;KafkaProducerWithCallbacks execution started.&quot;</span>);

          <span class="hljs-keyword">final</span> <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();
          <span class="hljs-comment">/*properties.setProperty(&quot;bootstrap.servers&quot;, &quot;[::1]:9092&quot;);
          properties.setProperty(&quot;key.serializer&quot;, StringSerializer.class.getName());
          properties.setProperty(&quot;value.serializer&quot;, StringSerializer.class.getName());*/</span>

          properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">&quot;[::1]:9092&quot;</span>);
          properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

          <span class="hljs-comment">//Kafka producer</span>
          KafkaProducer&lt;String, String&gt; producer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaProducer</span>&lt;&gt;(properties);

          <span class="hljs-comment">// send data and register callback for status</span>
          producer.send(<span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerRecord</span>&lt;&gt;(<span class="hljs-string">&quot;demo_java&quot;</span>, <span class="hljs-string">&quot;callback demo app&quot;</span>), <span class="hljs-keyword">new</span> <span class="hljs-title class_">Callback</span>() {
              <span class="hljs-comment">// Executes every time a message is successfully sent or exception occurs.</span>
              <span class="hljs-meta">@Override</span>
              <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onCompletion</span><span class="hljs-params">(RecordMetadata recordMetadata, Exception e)</span> {

                  <span class="hljs-comment">// check if no exception occurred</span>
                  <span class="hljs-keyword">if</span> (e == <span class="hljs-literal">null</span>) {
                      logger.info(<span class="hljs-string">&quot;Received new metadata. \nTopic: {}, \nPartition: {}, \nOffset: {}, \nTimestamp: {}&quot;</span>,
                              recordMetadata.topic(), recordMetadata.partition(),
                              recordMetadata.offset(), recordMetadata.timestamp());
                  } <span class="hljs-keyword">else</span> {
                      logger.error(<span class="hljs-string">&quot;Error while producing: {}&quot;</span>, e);
                  }
              }
          });
          <span class="hljs-comment">// flush and close</span>
          producer.flush();
          producer.close();

          logger.info(<span class="hljs-string">&quot;KafkaProducerWithCallbacks execution completed.&quot;</span>);
      }
  }
</code></pre>
</li>
<li>**Output: ** <em>IDE Console</em></li>
</ul>
<pre><code class="language-properties">    <span class="hljs-attr">[kafka-producer-network-thread</span> <span class="hljs-string">| producer-1] INFO com.srvivek.kafka.KafkaProducerWithCallbacks - Received new metadata. </span>
    <span class="hljs-attr">Topic</span>: <span class="hljs-string">demo_java, </span>
    <span class="hljs-attr">Partition</span>: <span class="hljs-string">2, </span>
    <span class="hljs-attr">Offset</span>: <span class="hljs-string">51, </span>
    <span class="hljs-attr">Timestamp</span>: <span class="hljs-string">1736577123225</span>
</code></pre>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://www.javatpoint.com/kafka-producer-callbacks">https://www.javatpoint.com/kafka-producer-callbacks</a></li>
<li><a href="https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/">https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="4-kafka-producers-inprovement-using-sticky-partitioner">4. Kafka Producers: Inprovement using sticky partitioner</h2>
<h3 id="project-ref-a3-kafka-partitioner-demo">Project ref: <a href="https://github.com/SRVivek1/kafka-for-beginners-2024/tree/main/03-kafka-beginners-gradle/a3-kafka-partitioner-demo">a3-kafka-partitioner-demo</a></h3>
<ul>
<li><strong><ins>Purpose / Feature</ins></strong>
<ul>
<li>The amount of time it takes for a message to move through a system plays a big role in the performance of distributed systems like Apache Kafka.
<ul>
<li>In Kafka, the latency of the producer is often defined as the time it takes for a message produced by the client to be acknowledged by Kafka.</li>
</ul>
</li>
<li>Each Kafka topic contains one or more partitions. When a Kafka producer sends a record to a topic, it needs to decide which partition to send it to. If we send several records to the same partition at around the same time, they can be sent as a batch.
<ul>
<li>Processing each batch requires a bit of overhead, with each of the records inside the batch contributing to that cost. Records in smaller batches have a higher effective cost per record. Generally, smaller batches lead to more requests and queuing, resulting in higher latency.</li>
</ul>
</li>
<li>A batch is completed either when it reaches a certain size (batch.size) or after a period of time (<a href="http://linger.ms">linger.ms</a>) is up. Both batch.size and <a href="http://linger.ms">linger.ms</a> are configured in the producer.
<ul>
<li>The default for <em><strong>batch.size</strong></em> is <em>16,384 bytes</em>, and the default of <em><strong><a href="http://linger.ms">linger.ms</a></strong></em> is <em>0</em> milliseconds.</li>
<li>Once batch.size is reached or at least <a href="http://linger.ms">linger.ms</a> time has passed, the system will send the batch as soon as it is able.</li>
</ul>
</li>
<li>Even when <a href="http://linger.ms">linger.ms</a> is 0, the producer will group records into batches when they are produced to the same partition around the same time. This is because the system needs a bit of time to handle each request, and batches form when the system cannot attend to them all right away.</li>
<li><strong>Partitioning strategy</strong>
<ul>
<li>If records are not sent to the same partition, they cannot form a batch together.</li>
<li>Kafka producers can configuring a Partitioner class to select partitioning strategy.
<ul>
<li>The Partitioner assigns the partition for each record.</li>
<li>The default behavior is to hash the key of a record to get the partition, but some records may have a key that is null.
<ul>
<li>In this case, the old partitioning strategy before Apache Kafka 2.4 would be to cycle through the topic’s partitions and send a record to each one.</li>
<li>Unfortunately, this method does not batch very well and may in fact add latency. Due to the potential for increased latency with small batches, the original strategy for partitioning records with null keys can be inefficient.</li>
<li>This changes with Apache Kafka 2.4, which introduces <em><strong>sticky partitioning</strong></em>, a new strategy for assigning records to partitions with proven lower latency.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Sticky partitioning strategy:</strong></li>
<li>The sticky partitioner addresses the problem of spreading out records without keys into smaller batches by picking a single partition to send all non-keyed records.
<ul>
<li>Once the batch at that partition is filled or otherwise completed, the sticky partitioner randomly chooses and “sticks” to a new partition.</li>
<li>That way, over a larger period of time, records are about evenly distributed among all the partitions while getting the added benefit of larger batch sizes.</li>
</ul>
</li>
<li>In order to change the sticky partition, Apache Kafka 2.4 also adds a new method called <em>onNewBatch</em> to the <em>Partitioner interface</em> for use right before a new batch is created, which is the perfect time to change the sticky partition. <em>DefaultPartitioner</em> implements this feature.<center>
 <img src="./images/kafka-sticking-partitioning-strategy.png" alt="Kafka Sticking Partitioning Strategy" title="Typical kafka streams ecosystem" width="600" height="300"/>
</li>
</ul>
  </center>
</li>
<li><strong><ins>Steps</ins></strong>
<ul>
<li><em><strong>Project Setup:</strong></em> Refer <em>Section-2 &amp; 3</em> for project setup.</li>
<li><em><strong>Step-1:</strong></em> Update ProducerConfig properties.
<ul>
<li><strong>Partitioner Class:</strong>
<ul>
<li><em>properties.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, RoundRobinPartitioner.class.getName());</em></li>
</ul>
</li>
<li><strong>Batch Size:</strong>
<ul>
<li><em>properties.setProperty(ProducerConfig.BATCH_SIZE_CONFIG, &quot;500&quot;);</em></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>Gradle / External dependency</ins></strong>
<ul>
<li>Required dependency.<pre><code class="language-groovy">      dependencies {
        implementation(<span class="hljs-string">&quot;org.apache.kafka:kafka-clients:3.9.0&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-api:2.0.16&quot;</span>)
        implementation(<span class="hljs-string">&quot;org.slf4j:slf4j-simple:2.0.16&quot;</span>)
      }
</code></pre>
</li>
</ul>
</li>
<li><strong><ins>Code / Config changes</ins></strong>
<ul>
<li><strong>Kafka Producer:</strong> <em>KafkaProducerPartitionerPoc.java</em>
<ul>
<li>imports
<ul>
<li><em>import org.apache.kafka.clients.producer.RoundRobinPartitioner;</em></li>
</ul>
</li>
<li>Configure Batch size and Partitioner class.<pre><code class="language-java">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">KafkaProducerPartitionerPoc</span> {

      <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">logger</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(KafkaProducerPartitionerPoc.class);

      <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {

          logger.info(<span class="hljs-string">&quot;execution started for main(...)&quot;</span>);

          <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();
          properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">&quot;[::1]:9092&quot;</span>);
          properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

          <span class="hljs-comment">// RoundRobin partitioner (Not rec. for PROD.)- send messages to each queue</span>
          <span class="hljs-comment">// Note: keep partitioner default as per kafka config</span>
          properties.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, RoundRobinPartitioner.class.getName());

          <span class="hljs-comment">//set batch size</span>
          <span class="hljs-comment">// Note: keep it default as per kafka config</span>
          properties.setProperty(ProducerConfig.BATCH_SIZE_CONFIG, <span class="hljs-string">&quot;500&quot;</span>);

          <span class="hljs-keyword">final</span> KafkaProducer&lt;String, String&gt; producer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaProducer</span>&lt;&gt;(properties);

          <span class="hljs-comment">// send data in multiple batches</span>
          <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {
              <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">30</span>; j++) {
                  producer.send(<span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerRecord</span>&lt;&gt;(<span class="hljs-string">&quot;demo_java&quot;</span>, String.format(<span class="hljs-string">&quot;Message: Hello World testing partitioner in kafka. Test [i: %s, j: %s]&quot;</span>, i, j)), <span class="hljs-keyword">new</span> <span class="hljs-title class_">Callback</span>() {
                      <span class="hljs-meta">@Override</span>
                      <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onCompletion</span><span class="hljs-params">(RecordMetadata recordMetadata, Exception e)</span> {
                          <span class="hljs-keyword">if</span> (e == <span class="hljs-literal">null</span>) {
                              logger.info(<span class="hljs-string">&quot;Record Metadata. \nTopic: {} \nPartition: {} \nOffset: {} \nTimestamp: {} \n&quot;</span>,
                                      recordMetadata.topic(), recordMetadata.partition(),
                                      recordMetadata.offset(), recordMetadata.timestamp());
                          } <span class="hljs-keyword">else</span> {
                              logger.error(<span class="hljs-string">&quot;Error: {}&quot;</span>, e.getStackTrace());
                          }
                      }
                  });
                  producer.flush();
              }
              <span class="hljs-comment">// sleep thread for 500ms</span>
              <span class="hljs-keyword">try</span> {
                  logger.info(<span class="hljs-string">&quot;Thread will sleep for 500ms.&quot;</span>);
                  Thread.sleep(<span class="hljs-number">500</span>);
              } <span class="hljs-keyword">catch</span> (InterruptedException e) {
                  <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);
              }
          }
          producer.close();
          logger.info(<span class="hljs-string">&quot;execution completed for main(...)&quot;</span>);
      }
  }
</code></pre>
</li>
<li><strong>Output:</strong> <em>IDE Console</em><pre><code class="language-properties"><span class="hljs-comment">    # FYI - it will send data to each parition in batches as batch theshhold is reached.</span>
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://www.redpanda.com/guides/kafka-tutorial-kafka-partition-strategy">https://www.redpanda.com/guides/kafka-tutorial-kafka-partition-strategy</a></li>
<li><a href="https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/">https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="5-kafka-producer-choose-partition-in-topic-using-key-in-record">5. Kafka Producer: Choose partition in topic using <em>key</em> in record</h2>
<h3 id="project-ref-a1-kafka-producer-1">Project ref: <a href="https://github.com/SRVivek1/kafka-for-beginners-2024/tree/main/03-kafka-beginners-gradle/a1-kafka-producer">a1-kafka-producer</a></h3>
<ul>
<li>
<p><strong><ins>About / Introduction</ins></strong></p>
<ul>
<li>Along side the message value, we can choose to send a message key and that key could be a string, a number etc type.
<ul>
<li>This is an important property of Kafka which helps us to preserve the ordering for messages with specific field by passing same key for these kind of messages by sending all the messages that share the same key to the same partition.</li>
<li>When we don’t send the key, the key is set to <em>null</em> and the data will be sent to randomly selected patition as <em>Partitioning class / strategy</em>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><ins>Steps</ins></strong></p>
<ul>
<li><em><strong>Project Setup:</strong></em> Create Kafka Producer application.
<ul>
<li>Refer above <em>section-2 to 4</em> for project setup.</li>
</ul>
</li>
<li><em><strong>Step-1:</strong></em> Update <em>ProducerRecord</em> to include <em>key</em> along with <em>message</em> &amp; <em>topic name</em>.
<ul>
<li><em>ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(TOPIC, key, message)</em></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>App:</strong> <em>KafkaProducerRecordWithKeys.java</em>
```java
public class KafkaProducerRecordWithKeys {
private static final Logger logger = LoggerFactory.getLogger(KafkaProducerRecordWithKeys.class);</p>
<pre><code>      public static void main(String[] args) {
          logger.info(&quot;Execution started for main(...)&quot;);

          final Properties properties = new Properties();
          properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;[::1]:9092&quot;);
          properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

          final KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties);

          final String TOPIC = &quot;demo_java&quot;;
          // Send data
          for (int j = 0; j &lt; 10; j++) {
              for (int i = 0; i &lt; 10; i++) {

                  String key = &quot;id_&quot; + i;
                  String message = &quot;hello world - &quot; + i;

                  producer.send(new ProducerRecord&lt;&gt;(TOPIC, key, message), new Callback() {
                      @Override
                      public void onCompletion(RecordMetadata recordMetadata, Exception e) {

                          if (e == null) {
                              logger.info(&quot;Record: Key: {}, Partition: {}&quot;, key, recordMetadata.partition());
                          } else {
                              logger.error(&quot;Stacktrace:\n{}&quot;, e.getStackTrace());
                          }
                      }
                  });
                  producer.flush();
              }
              // sleep thead to create bataches
              try {
                  Thread.sleep(1000);
              } catch (InterruptedException e) {
                  throw new RuntimeException(e);
              }
          }
          producer.close();
          logger.info(&quot;Execution completed for main(...)&quot;);
      }
  }
```
</code></pre>
</li>
<li>
<p><strong><ins>References:</ins></strong></p>
<ul>
<li><a href="https://www.geeksforgeeks.org/apache-kafka-message-keys/">https://www.geeksforgeeks.org/apache-kafka-message-keys/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="6-kafka-consumer-read-data-from-topic">6. Kafka Consumer: Read data from topic</h2>
<h3 id="project-ref-a4-kafka-consumer">Project ref: <a href="https://github.com/SRVivek1/kafka-for-beginners-2024/tree/main/03-kafka-beginners-gradle/a4-kafka-consumer">a4-kafka-consumer</a></h3>
<ul>
<li><strong><ins>Purpose / Feature</ins></strong>
<ul>
<li>An Apache Kafka® Consumer is a client application that subscribes to (reads and processes) events from Kafka Topics.</li>
<li>The Kafka consumer works by issuing “fetch” requests to the brokers (kafka server) leading the partitions it wants to consume.
<ul>
<li>The consumer offset is specified in the log with each request.</li>
<li>The consumer receives back a chunk of log that contains all of the messages in that topic beginning from the offset position.</li>
<li>The consumer has significant control over this position and can rewind it to re-consume data if desired.</li>
</ul>
</li>
<li>To use the <em>subscribe</em> or <em>commit</em> methods provided by the KafkaConsumer API, we must assign the consumer to a <em>consumer group</em> by setting the <em><strong><a href="http://group.id">group.id</a></strong></em> property.
<ul>
<li>If consumer is not part of any group, then an exception is thrown when these methods are called.</li>
</ul>
</li>
<li><strong>Offset management:</strong>
<ul>
<li>After the consumer receives its assignment from the coordinator, it must determine the initial position for each assigned partition.</li>
<li>When the group is first created, before any messages have been consumed, the position is set according to a configurable offset reset policy (auto.offset.reset).
<ul>
<li>Typically, consumption starts either at the <em>earliest offset</em> or the <em>latest offset</em>.</li>
</ul>
</li>
<li><strong>Property: <em>auto.offset.reset:</em></strong>
<ul>
<li>Following are 3 possible values:
<ul>
<li><strong>none:</strong> <em>Fail if the consumer group doesn't exists.</em></li>
<li><strong>earliest:</strong> <em>Read events from beginning</em></li>
<li><strong>latest:</strong> <em>Read new messages/events</em></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>Steps</ins></strong>
<ul>
<li><em><strong>Project Setup:</strong></em></li>
<li>Create a gradle project using intellij IDEA IDE or by visiting <em><a href="https://start.spring.io/">https://start.spring.io/</a></em>.</li>
<li>Delete <code>src</code> folder from project home directory.</li>
<li><em><strong>Step-1:</strong></em> Create a <em>new module</em> inside project.
<ul>
<li><strong>Steps:</strong> Right Click on the project --&gt; New --&gt; Module
<ul>
<li>Select appropriate option on the given form and click <em>Create</em>.</li>
</ul>
</li>
</ul>
</li>
<li><em><strong>Step-2:</strong></em> Add following dependencies.
<ul>
<li><strong>Kafka Clients:</strong> <em>implementation(&quot;org.apache.kafka:kafka-clients:3.9.0&quot;)</em></li>
<li><strong>Slf4j API:</strong> <em>implementation(&quot;org.slf4j:slf4j-api:2.0.16&quot;)</em></li>
<li><strong>Slf4j Simple:</strong> <em>implementation(&quot;org.slf4j:slf4j-simple:2.0.16&quot;)</em></li>
</ul>
</li>
<li><em><strong>Step-3:</strong></em> Create properties for target Kafka server.</li>
<li><em><strong>Step-4:</strong></em> Add properties for Consumer Configs e.g. key and value deserializer, group id etc.</li>
<li><em><strong>Step-5:</strong></em> Add Consumer config property <em>auto.offset.reset</em></li>
<li><em><strong>Step-6:</strong></em> Create <em>KafkaConsumer</em> instance.</li>
<li><em><strong>Step-7:</strong></em> Create shutdown hook to current <em>Runtime</em> and join the Main Thread.
<ul>
<li><em>kafkaConsumer.wakeup():</em> Once this API is called, <em>Consumer</em> will throws exception on next <em>poll(..)</em> API invocation.
<ul>
<li><strong>kafkaConsumer.wakeup():</strong>
<ul>
<li>Wakeup the consumer. This method is thread-safe and is useful in particular to abort a long poll.</li>
<li>The thread which is blocking in an operation will throw <em>org.apache.kafka.common.errors.WakeupException</em>.</li>
<li>If no thread is blocking in a method which can throw <em>org.apache.kafka.common.errors.WakeupException</em>, the next call to such a method will raise it instead.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><em><strong>Step-8</strong></em> Handle <em>WakeupException</em> with <em>poll(..)</em> call and process graceful shutdown.</li>
<li><em><strong>Step-9:</strong></em> Subscribe to kafka topic using <em>KafkaConsumer.subscribe(..) API</em>.</li>
<li><em><strong>Step-10:</strong></em> Poll for the data using <em>KafkaConsumer.poll(..) API</em>.</li>
<li><em><strong>Step-11:</strong></em> Iterate over the <em>ConsumerRecord</em> list and process it.</li>
<li><em><strong>Step-12:</strong></em> Graceful shudown of java app
<ul>
<li><strong>1.</strong> Attach <em>shutdownHook</em> to <em>Runtime</em> and pass a new thread to call <em>kafkaConsumer.wakeup()</em>, which will raise <em>WakeupException</em> if <em>poll(..)</em> is called.</li>
<li><strong>2.</strong> Catch the exception and close open resources of kafka.</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>Code </ins></strong>
<ul>
<li><strong>Consumer:</strong> <em>KafkaConsumerApp.java</em>
<ul>
<li>imports
<ul>
<li><em>import org.apache.kafka.clients.consumer.ConsumerConfig;</em></li>
<li><em>import org.apache.kafka.clients.consumer.ConsumerRecord;</em></li>
<li><em>import org.apache.kafka.clients.consumer.ConsumerRecords;</em></li>
<li><em>import org.apache.kafka.clients.consumer.KafkaConsumer;</em></li>
<li><em>import org.apache.kafka.common.errors.WakeupException;</em></li>
</ul>
</li>
<li>Kafka Consumer class to poll messages from kafka.<pre><code class="language-java">  <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">KafkaConsumerApp</span> {

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">logger</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(KafkaConsumerApp.class);
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">GROUP_ID</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;my-java-app-consumers&quot;</span>;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">TOPIC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;demo_java&quot;</span>;

    <span class="hljs-comment">/**
    * Kafka consumer configuration
    */</span>
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Properties <span class="hljs-title function_">getKafkaConfig</span><span class="hljs-params">()</span> {

        <span class="hljs-keyword">final</span> <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">&quot;[::1]:9092&quot;</span>);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        <span class="hljs-comment">// set application group id</span>
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);

        <span class="hljs-comment">// Read config</span>
        <span class="hljs-comment">//Read only new messages</span>
        <span class="hljs-comment">// properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;);</span>
        <span class="hljs-comment">// --&gt; fail if consumer group doesn&#x27;t exist</span>
        <span class="hljs-comment">// properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;none&quot;);</span>
        <span class="hljs-comment">// --&gt; Read from beginning</span>
        properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="hljs-string">&quot;earliest&quot;</span>);

        <span class="hljs-comment">// Don&#x27;t create topics if not found.</span>
        properties.setProperty(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.toString(<span class="hljs-literal">false</span>));

        <span class="hljs-keyword">return</span> properties;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {

        logger.info(<span class="hljs-string">&quot;Execution started of main(...)&quot;</span>);

        <span class="hljs-comment">// Create consumer</span>
        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaConsumer</span>&lt;&gt;(getKafkaConfig());

        <span class="hljs-comment">//Add shutdown hook to gracefully close the consumer</span>
        <span class="hljs-keyword">final</span> <span class="hljs-type">Thread</span> <span class="hljs-variable">mainThread</span> <span class="hljs-operator">=</span> Thread.currentThread();
        Runtime.getRuntime().addShutdownHook(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>() {
            <span class="hljs-meta">@Override</span>
            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> {
                logger.info(<span class="hljs-string">&quot;Detected shutdown. calling to initiate shutdown.&quot;</span>);
                kafkaConsumer.wakeup();

                <span class="hljs-keyword">try</span> {
                    mainThread.join();
                } <span class="hljs-keyword">catch</span> (InterruptedException e) {
                    logger.error(<span class="hljs-string">&quot;Shutdown error while waiting for consumer to close resources. Message: {}&quot;</span>, e.getMessage());
                    e.printStackTrace();
                    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);
                }
            }
        });

        <span class="hljs-keyword">try</span> {
            <span class="hljs-comment">//subscribe</span>
            kafkaConsumer.subscribe(List.of(TOPIC));

            <span class="hljs-comment">// Poll for events</span>
            <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) {

                logger.info(<span class="hljs-string">&quot;Polling.................&quot;</span>);
                <span class="hljs-comment">// The maximum time to block.</span>
                <span class="hljs-comment">// Must not be greater than Long.MAX_VALUE milliseconds.</span>
                <span class="hljs-keyword">final</span> ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(<span class="hljs-number">1000</span>));

                <span class="hljs-keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) {
                    logger.info(<span class="hljs-string">&quot;Key: {}, Value: {}&quot;</span>, record.key(), record.value());
                    logger.info(<span class="hljs-string">&quot;Partition: {}, Offset: {}&quot;</span>, record.partition(), record.offset());
                }
            }
        } <span class="hljs-keyword">catch</span> (WakeupException we) {
            logger.info(<span class="hljs-string">&quot;Started shutdown for consumer.&quot;</span>);
        } <span class="hljs-keyword">catch</span> (Exception e) {
            logger.error(<span class="hljs-string">&quot;Unexpected error in consumer. Message: {}&quot;</span>, e.getMessage());
            e.printStackTrace();
        } <span class="hljs-keyword">finally</span> {
            kafkaConsumer.close();
            logger.info(<span class="hljs-string">&quot;Consumer is now gracefully shutdown.&quot;</span>);
        }
        logger.info(<span class="hljs-string">&quot;Execution completed of main(...)&quot;</span>);
    }
}
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://docs.confluent.io/platform/current/clients/consumer.html">https://docs.confluent.io/platform/current/clients/consumer.html</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="7-consumer-group-and-rebalancing">7. Consumer group and rebalancing</h2>
<ul>
<li><strong><ins>About / Introduction</ins></strong>
<ul>
<li>The concept of rebalancing is fundamental to Kafka's consumer group architecture. When a consumer group is created, the group coordinator assigns partitions to each consumer in the group. Each consumer is responsible for consuming data from its assigned partitions.</li>
<li>However, as consumers join or leave the group or new partitions are added to a topic, the partition assignments become unbalanced. This is where rebalancing comes into play.
<ul>
<li>Kafka rebalancing is the process by which Kafka redistributes partitions across consumers to ensure that each consumer is processing an approximately equal number of partitions.</li>
<li>This ensures that data processing is distributed evenly across consumers and that each consumer is processing data as efficiently as possible.</li>
<li>As a result, Kafka can scale efficiently and effectively, preventing any single consumer from becoming overloaded or underused.</li>
</ul>
</li>
<li><strong>Rebalacing:</strong>
<ul>
<li><em><strong>Eager Rebalance</strong></em>
<ul>
<li>All consumers are stopped and giveup their membership of partitions.</li>
<li>They rejoin the consumer group and get a new partition assignment.
<ul>
<li>During this rejoining process entire consumer gropu stops processing, commonly called a “<em>stop the world effect</em>”. This causes delays and interruptions in data processing.</li>
<li>There's no gurantee that consumers will get the same pastitions assignmend again.</li>
</ul>
</li>
<li><strong>How to use ?</strong>
<ul>
<li>Set Kafka Consumer configuration <em>partition.assignment.strategy</em>.
<ul>
<li><em>RangeAssignor:</em>
<ul>
<li>Assigns partition on per-topic basis (can lead to imbalance).</li>
</ul>
</li>
<li><em>RoundRobin:</em>
<ul>
<li>Assigns partitions across all topics in round-robin fashion (optimal balance).</li>
</ul>
</li>
<li><em>StickyAssignor:</em>
<ul>
<li>Balanced like <em>RoundRobin</em> and minimizes parition movements when consumer joins or leaves the group.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><em><strong>Cooperative (Incremental) Rebalance:</strong></em>
<ul>
<li>Incremental cooperative rebalance protocol was introduced in Kafka 2.4 to minimize the disruption caused by Kafka rebalancing.</li>
<li>In this strategy rebalancing is split into smaller sub-tasks, and consumers continue consuming data while these sub-tasks are completed. As a result, rebalancing occurs more quickly and with less interruption to data processing.</li>
<li>It can go through several itertions to find a stable assignment (hence incremental).</li>
<li>The protocol also provides more fine-grained control over the rebalancing process.
<ul>
<li><em><strong>For example,</strong></em> it allows consumers to negotiate the specific set of partitions they will consume based on their current load and capacity. This prevents the overloading of individual consumers and ensures that partitions are assigned in a more balanced way.</li>
</ul>
</li>
<li><strong>How to use ?</strong>
<ul>
<li>Set Kafka Consumer configuration <em>partition.assignment.strategy</em>.
<ul>
<li><em>CooperativeStickyAssignor</em>
<ul>
<li>Identical to <em>StickyAssignor</em> but supports <em>cooperative rebalance</em> and therefore consumers can keep consuming from the Topic.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>How rebalancing works</strong>
<ul>
<li>Kafka provides several partition assignment strategies to determine how partitions are assigned during a rebalance and is called an “assignor”.</li>
<li>The default partition assignment strategy is round-robin, where Kafka assigns partitions to consumers one after another.</li>
<li>However, Kafka also provides “range” and “cooperative sticky” assignment strategies, which may be more appropriate for specific use cases.</li>
</ul>
</li>
<li><strong>When a rebalance occurs:</strong>
<ul>
<li>Kafka notifies each consumer in the group by sending a GroupCoordinator message.</li>
<li>Each consumer then responds with a JoinGroup message, indicating its willingness to participate in the rebalance.</li>
<li>Kafka then uses the selected partition assignment strategy to assign partitions to each consumer in the group.</li>
<li><strong>Note:</strong>
<ul>
<li>During a rebalance, Kafka may need to pause data consumption temporarily.</li>
<li>This is necessary to ensure all consumers have an up-to-date view of the partition assignments before re-consuming data.</li>
</ul>
</li>
</ul>
</li>
<li><strong>What triggers Kafka rebalancing ?</strong>
<ul>
<li><em>Consumer joins or leaves</em></li>
<li><em>Temporary consumer failure</em></li>
<li><em>Consumer idle for too long</em></li>
<li><em>Topic partitions added</em></li>
</ul>
</li>
<li><strong>Side effects of Kafka rebalancing</strong>
<ul>
<li><em>Increased latency</em></li>
<li><em>Reduced throughput</em></li>
<li><em>Increased resource usage</em></li>
<li><em>Increased complexity</em></li>
<li><em>Potential data duplication and loss</em></li>
</ul>
</li>
<li><strong>Measures to reduce rebalancing:</strong>
<ul>
<li><em>Increase session timeout</em>
<ul>
<li>The session timeout is the maximum time for a Kafka consumer to send a heartbeat to the broker.</li>
<li>Increasing the session timeout increases the time a broker waits before marking a consumer as inactive.
<ul>
<li>Set the <em><a href="http://session.timeout.ms">session.timeout.ms</a></em> parameter to a higher value in the Kafka client configuration to increate session timeout.</li>
<li>However, setting this parameter too high leads to longer periods of consumer inactivity.</li>
</ul>
</li>
</ul>
</li>
<li><em>Reduce partitions per topic</em>
<ul>
<li>Having too many partitions per topic increases the frequency of rebalancing.</li>
<li>When creating a topic, set the partition number by setting the <em>num.partitions</em> parameter to a lower value.
<ul>
<li>However, reducing the number of partitions also reduces the parallelism and throughput of your Kafka cluster.</li>
</ul>
</li>
</ul>
</li>
<li><em>Increase poll interval time</em>
<ul>
<li>Sometimes messages take longer to process due to multiple network or I/O calls involved in processing failures and retries. In such cases, the consumer may be removed from the group frequently.</li>
<li>Set the consumer configuration <em><a href="http://max.poll.interval.ms">max.poll.interval.ms</a></em> with the maximum time the consumer can be idle before it is considered inactive and removed from the group.</li>
<li>Increasing the <a href="http://max.poll.interval.ms">max.poll.interval.ms</a> value in the consumer config helps avoid frequent consumer group changes.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Static group membership rebalancing?  <em>-- Not Recommended</em></strong>
<ul>
<li>It's a method of assigning Kafka partitions to consumers in a consumer group in a fixed and deterministic way without relying on automatic partition assignment.
<ul>
<li>In this approach, the developer defines the partition assignment explicitly instead of letting the Kafka broker manage it dynamically.</li>
</ul>
</li>
<li>With static group membership, consumers in a consumer group explicitly request the Kafka broker to assign them specific partitions by specifying the partition IDs in their configuration.</li>
<li>Each consumer only consumes messages from a specific subset of partitions, and the partition assignment remains fixed until explicitly changed by the consumer.
<ul>
<li><em>However, it's important to note that static group membership leads to <em><strong>uneven workload distribution</strong></em> among consumers and may only be suitable for some use cases</em>.</li>
<li><strong>Note:</strong> This is helpful when sonsumers maintain local state and cache (to avoid re-building the cache).</li>
</ul>
</li>
<li><strong>How to use ?:</strong>
<ul>
<li>Set the configuration <em><a href="http://group.instance.id">group.instance.id</a></em> to make a consumer a static member.</li>
<li>The same partition will be assigned to consumer if it rejoins before the session timeout <em><a href="http://session.timeout.ms">session.timeout.ms</a></em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><ins>References:</ins></strong>
<ul>
<li><a href="https://www.redpanda.com/guides/kafka-performance-kafka-rebalancing">https://www.redpanda.com/guides/kafka-performance-kafka-rebalancing</a></li>
</ul>
</li>
</ul>
<hr>

            
            
        </body>
        </html>
